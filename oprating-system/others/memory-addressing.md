 # 内存地址

<!-- TOC -->

- [1. 内存地址](#1-内存地址)
- [2. 内存仲裁器](#2-内存仲裁器)
- [3. 高速缓存(cache)](#3-高速缓存cache)

<!-- /TOC -->

本篇笔记主要关于Linux下的内存结构，以及进程的内存管理。涵盖从内存寻址到内存管理的内容。


# 1. 内存地址

首先明确为什么要有内存寻址技术。在该技术出现之前，内存对于程序是完全透明的。程序可以访问每一块内存单元，不论该内存单元属于谁，是否正在被使用。这时的内存管理，完全依赖程序自觉。程序可能由于各种边界条件而访问、修改属于其他程序的数据。严重些的，还可能破坏系统内核的数据。

为了解决这一问题，前人提出了分段和分页的方法。


先学会区分以下三种地址：
* 逻辑地址(logical address)
* 线性地址(linear address / virtual address)
* 物理地址(physical address)

1. 逻辑地址直接面向应用程序，由段标识符和相对地址的偏移量组成。逻辑地址的意义在于从应用程序的角度访问内存，使程序以为需要的数据/指令在内存某个单元上（逻辑地址），实际上该地址会经过映射转化为真正的物理地址，也就是存储单元的真实位置。

2. 物理地址面向cpu，它是硬件级别的地址，和地址总线上的电信号对应。

3. 线性地址暂时不考虑，三者混在一起难以理解，没有意义。

程序的内存寻址过程是：
```
逻辑地址 --> (分段单元) --> 线性地址 --> (分页单元) --> 物理地址
```

# 2. 内存仲裁器
由于内存单元不能由多个指令同时访问，必须进行同步限制。同步限制主要作用于  
* cpu和内存之间
* DMA和内存之间

单核处理器系统下，内存仲裁器用于解决DMA和CPU对内存的竞争使用；多核处理器下，内存仲裁器**还**用于解决不同cpu之间对内存的竞争使用。

可以看出，内存仲裁器的构造非常复杂，需要和多个cpu、DMA通道、内存直接连接，

# 3. 高速缓存(cache)
cache的意义在于解决cpu的时钟频率和内存的存取时间不匹配问题。在相同时间内，cpu可以处理的指令条数是内存存取次数的数百倍。大个比方，cpu花一秒来发出一条指令，内存需要过100秒才能把数据送回cpu，而cpu就需要花99秒去等待数据，这显然存在着cpu资源的浪费。

理想情况是，cpu保持工作，尽量不浪费任何一个时钟周期。在多核cpu系统中，每个cpu单元都有自己的高速缓存，cpu访问高速缓存的速度远快于cpu访问内存的速度，同时高速缓存较小（几M）,可以保存cpu最近经常要用的内存块，通过缓存命中来提高整体处理速度。


||缓存命中|没有命中缓存|
|-|-|-|
|读操作|cpu直接从cache获取数据|高速缓存被写回内存，并装入新的内存块|
|写操作|通写(write-through)或回写(write-back)|高速缓存被写回内存，并装入新的内存块|

write-through和write-back用于保证缓存和内存的数据一致性。不同的是，write-through是同时更新缓存和内存；write-back只更新缓存，在缓存被装回内存时，内存被更新。显然write-back要更快一些。

在多核系统中，还要考虑同一内存块被装入多个cpu后的数据同步问题，这里不再研究。